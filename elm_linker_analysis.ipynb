{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42665fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Setup and Configuration\n",
    "\n",
    "Load required libraries and set working directory.\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Configuration\n",
    "workdir = \"~/Desktop/work/protein_linkers/input_2\"\n",
    "workdir = os.path.expanduser(workdir)\n",
    "elm_path = os.path.join(workdir, 'elm', 'elm_results.json')\n",
    "fasta_path = os.path.join(workdir, 'proteins.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Load Linker + Domain Data\n",
    "\n",
    "Load the three clustered linker dictionaries (short, medium, long) that were\n",
    "generated by the clustering analysis, plus the filtered proteins dictionary\n",
    "with all domains and linkers.\n",
    "\"\"\"\n",
    "\n",
    "# Load short linkers\n",
    "short_linkers_path = os.path.join(workdir, 'short_linkers.json')\n",
    "with open(short_linkers_path, 'r') as f:\n",
    "    short_linkers = json.load(f)\n",
    "\n",
    "# Load medium linkers\n",
    "medium_linkers_path = os.path.join(workdir, 'medium_linkers.json')\n",
    "with open(medium_linkers_path, 'r') as f:\n",
    "    medium_linkers = json.load(f)\n",
    "\n",
    "# Load long linkers\n",
    "long_linkers_path = os.path.join(workdir, 'long_linkers.json')\n",
    "with open(long_linkers_path, 'r') as f:\n",
    "    long_linkers = json.load(f)\n",
    "\n",
    "# Load filtered proteins (contains all domains and linkers after outlier removal)\n",
    "filtered_proteins_path = os.path.join(workdir, 'filtered_proteins.json')\n",
    "with open(filtered_proteins_path, 'r') as f:\n",
    "    filtered_proteins = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b075fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Load Protein Sequences\n",
    "\n",
    "Load the FASTA file to extract linker sequences for ELM analysis.\n",
    "\"\"\"\n",
    "\n",
    "def load_fasta(fasta_path):\n",
    "    \"\"\"\n",
    "    Load protein sequences from a FASTA file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    fasta_path : str\n",
    "        Path to FASTA file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with protein accessions as keys and sequences as values\n",
    "    \"\"\"\n",
    "    sequences_dict = {}\n",
    "\n",
    "    with open(fasta_path, 'r') as f:\n",
    "        current_acc = None\n",
    "        current_seq = []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                # Save previous sequence if exists\n",
    "                if current_acc:\n",
    "                    sequences_dict[current_acc] = ''.join(current_seq)\n",
    "\n",
    "                # Start new sequence\n",
    "                current_acc = line[1:]\n",
    "                current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line)\n",
    "\n",
    "        # Save last sequence\n",
    "        if current_acc:\n",
    "            sequences_dict[current_acc] = ''.join(current_seq)\n",
    "\n",
    "    return sequences_dict\n",
    "\n",
    "\n",
    "# Load sequences\n",
    "sequences_dict = load_fasta(fasta_path)\n",
    "\n",
    "print(f\"âœ“ Loaded {len(sequences_dict)} protein sequences from proteins.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc4b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELM DICTIONARY SUMMARY\n",
      "============================================================\n",
      "\n",
      "DOMAINS:\n",
      "\n",
      "  Number of regions: 591\n",
      "\n",
      "  Total motif instances: 19094\n",
      "\n",
      "  Example: P69905_domain_1_Hemoglobin and related oxygen transporters\n",
      "\n",
      "    - Length: 142 aa\n",
      "\n",
      "    - Motif count: 24\n",
      "\n",
      "    - First motif: CLV_PCSK_SKI1_1\n",
      "\n",
      "\n",
      "N-TERMINUS:\n",
      "\n",
      "  Number of regions: 30\n",
      "\n",
      "  Total motif instances: 332\n",
      "\n",
      "  Example: Q9H3U1_linker_1_n-terminus\n",
      "\n",
      "    - Length: 17 aa\n",
      "\n",
      "    - Motif count: 9\n",
      "\n",
      "    - First motif: CLV_PCSK_SKI1_1\n",
      "\n",
      "\n",
      "C-TERMINUS:\n",
      "\n",
      "  Number of regions: 32\n",
      "\n",
      "  Total motif instances: 177\n",
      "\n",
      "  Example: P00533_linker_2_c-terminus\n",
      "\n",
      "    - Length: 6 aa\n",
      "\n",
      "    - Motif count: 3\n",
      "\n",
      "    - First motif: DEG_Cend_KLHDC2_1\n",
      "\n",
      "\n",
      "INNER:\n",
      "\n",
      "  Number of regions: 85\n",
      "\n",
      "  Total motif instances: 1297\n",
      "\n",
      "  Example: Q9Y6K9_linker_2_inner\n",
      "\n",
      "    - Length: 16 aa\n",
      "\n",
      "    - Motif count: 3\n",
      "\n",
      "    - First motif: CLV_PCSK_KEX2_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "elm_dict = {\n",
    "    'domains': {protein_domain_id: region_info, ...},\n",
    "    'n-terminus': {protein_linker_id: region_info, ...},\n",
    "    'c-terminus': {protein_linker_id: region_info, ...},\n",
    "    'inner': {protein_linker_id: region_info, ...}\n",
    "}\n",
    "\n",
    "where region_info = {\n",
    "    'region_id': str,           # e.g., 'Q9Y6K9_linker_2_inner'\n",
    "    'region_type': str,         # 'domain', 'n-terminus', 'c-terminus', or 'inner'\n",
    "    'sequence_length': int,     # length of the region in amino acids\n",
    "    'motifs': {\n",
    "        'MOTIF_NAME': {\n",
    "            'start': int,       # start position within the region (1-based)\n",
    "            'end': int          # end position within the region (1-based)\n",
    "        },\n",
    "        ...\n",
    "    },\n",
    "    'motif_count': int          # total number of motifs found in this region\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(elm_path, 'r') as f:\n",
    "    elm_dict = json.load(f)\n",
    "\n",
    "print(\"ELM DICTIONARY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "for category, regions in elm_dict.items():\n",
    "    print(f\"\\n{category.upper()}:\\n\")\n",
    "    print(f\"  Number of regions: {len(regions)}\\n\")\n",
    "\n",
    "    # Count total motifs in this category\n",
    "    total_motifs = sum(region_info['motif_count'] for region_info in regions.values())\n",
    "    print(f\"  Total motif instances: {total_motifs}\\n\")\n",
    "\n",
    "    # Show example\n",
    "    if regions:\n",
    "        example_id = list(regions.keys())[0]\n",
    "        example = regions[example_id]\n",
    "        print(f\"  Example: {example_id}\\n\")\n",
    "        print(f\"    - Length: {example['sequence_length']} aa\\n\")\n",
    "        print(f\"    - Motif count: {example['motif_count']}\\n\")\n",
    "        if example['motifs']:\n",
    "            first_motif = list(example['motifs'].keys())[0]\n",
    "            print(f\"    - First motif: {first_motif}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
